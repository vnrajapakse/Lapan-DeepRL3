<h1 align="center">
Deep Reinforcement Learning Hands-On, Third Edition</h1>
<p align="center">This is the code repository for <a href ="https://www.packtpub.com/en-us/product/deep-reinforcement-learning-hands-on-third-edition/9781835882702"> Deep Reinforcement Learning Hands-On, Third Edition</a>, published by Packt.
</p>

---

### üìò About This Fork

This is a personal fork of [Maxim Lapan‚Äôs *Deep Reinforcement Learning Hands-On (3rd Edition)*](https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On-Third-Edition).

I‚Äôm using it for self-study, annotation, and refactoring. I may also adapt code for domain-specific RL experiments.
The original README follows below.

<h2 align="center">
A practical and easy-to-follow guide to RL from Q-learning and DQNs to PPO and RLHF
</h2>
<p align="center">
Maxim Lapan</p>

<p align="center">
   <a href="https://packt.link/rl" alt="Discord" title="Learn more on the Discord server"><img width="32px" src="https://cliply.co/wp-content/uploads/2021/08/372108630_DISCORD_LOGO_400.gif"/></a>
  &#8287;&#8287;&#8287;&#8287;&#8287;
  <a href="https://packt.link/free-ebook/9781835882702"><img width="32px" alt="Free PDF" title="Free PDF" src="https://cdn-icons-png.flaticon.com/512/4726/4726010.png"/></a>
 &#8287;&#8287;&#8287;&#8287;&#8287;
  <a href="https://packt.link/gbp/9781835882702"><img width="32px" alt="Graphic Bundle" title="Graphic Bundle" src="https://cdn-icons-png.flaticon.com/512/2659/2659360.png"/></a>
  &#8287;&#8287;&#8287;&#8287;&#8287;
   <a href="https://www.amazon.com/Reinforcement-Learning-Hands-easy-follow/dp/1835882706/"><img width="32px" alt="Amazon" title="Get your copy" src="https://cdn-icons-png.flaticon.com/512/15466/15466027.png"/></a>
  &#8287;&#8287;&#8287;&#8287;&#8287;
</p>
<details open> 
  <summary><h2>About the book</summary>
<a href="https://www.packtpub.com/product/unity-cookbook-fifth-edition/9781805123026">
<img src="https://content.packt.com/B22150/cover_image_small.jpg" alt="Unity Cookbook, Fifth Edition" height="256px" align="right">
</a>

Reward yourself and take this journey into RL with the third edition of Deep Reinforcement Learning Hands-On. The book takes you through the basics of RL to more advanced concepts with the help of various applications, including game playing, discrete optimization, stock trading, and web browser navigation. By walking you through landmark research papers in the field, this deep reinforcement learning book will equip you with the practical know-how of RL and the theoretical foundation to understand and implement most modern RL papers.
The book retains its strengths by providing concise and easy-to-follow explanations. You‚Äôll work through practical and diverse examples, from grid environments and games to stock trading and RL agents in web environments, to give you a well-rounded understanding of RL, its capabilities, and use cases. You‚Äôll learn about key topics, such as deep Q-networks (DQNs), policy gradient methods, continuous control problems, and highly scalable, non-gradient methods.
If you want to learn about RL using a practical approach using OpenAI  Gym and PyTorch , concise explanations, and the incremental development of topics, then Deep Reinforcement Learning Hands-On, Third Edition is your ideal companion</details>
<details open> 
  <summary><h2>Key Learnings</summary>
<ul>

<li>Stay on the cutting edge with new content on MuZero, RL with human feedback, and LLMs</li>

<li>Evaluate RL methods, including cross-entropy, DQN, actor-critic, TRPO, PPO, DDPG, and D4PG</li>

<li>Implement RL algorithms using PyTorch and modern RL libraries</li>

<li>Build and train deep Q-networks to solve complex tasks in Atari environments</li>

<li>Speed up RL models using algorithmic and engineering approaches</li>

<li>Leverage advanced techniques like proximal policy optimization (PPO) for more stable training</li>

</ul>

  </details>

<details open> 
  <summary><h2>Chapters</summary>
     <img src="https://cliply.co/wp-content/uploads/2020/02/372002150_DOCUMENTS_400px.gif" alt="Unity Cookbook, Fifth Edition" height="556px" align="right">
<ol>

  <li> What Is Reinforcement Learning?</li>

  <li> OpenAI Gym </li>

  <li>Deep Learning with PyTorch</li>

  <li>The Cross-Entropy Method</li>

  <li>Tabular Learning and the Bellman Equation</li>

  <li>Deep Q-Networks</li>

  <li>Higher-Level RL Libraries</li>

  <li>DQN Extensions </li>

  <li>Ways to Speed up RL</li>

  <li>Stocks Trading Using RL</li>

  <li>Policy Gradients ‚Äì an Alternative</li>

  <li>Actor-Critic Methods - A2C and A3C</li>

  <li>The TextWorld Environment</li>

  <li>Web Navigation</li>

  <li>Continuous Action Space</li>

  <li>Trust Regions ‚Äì PPO, TRPO, ACKTR, and SAC</li>

  <li>Black-Box Optimization in RL</li>

  <li>Advanced Exploration</li>

  <li>RL with Human Feedback</li>

  <li>MuZero</li>

  <li>RL in Discrete Optimization</li>

  <li>Multi-agent RL</li>

</ol>

</details>


<details open> 
  <summary><h2>Requirements for this book</summary>

The examples in this book were implemented and tested using Python version 3.11. I assume that you‚Äôre
already familiar with the language and common concepts such as virtual environments, so I won‚Äôt cover in
detail how to install packages and how to do this in an isolated way. The examples will use the previously
mentioned Python type annotations, which will allow us to provide type signatures for functions and class
methods.
Nowadays, there are lots of ML and RL libraries available, but in this book, I tried to keep the list of dependencies
to a minimum, giving a preference to our own implementation of methods over the blind import of third-party
libraries.
The external libraries that we will use in this book are open source software, and they include the following:

- **NumPy**: This is a library for scientific computing and implementing matrix operations and common functions.
- **OpenCV Python bindings**: This is a computer vision library and provides many functions for image processing.
- **Gymnasium from the Farama Foundation**: (https://farama.org) This is a maintained fork of the OpenAI Gym library (https://github.com/openai/gym) and an RL framework that has various environments that can be communicated with in a unified way.
- **PyTorch**: This is a flexible and expressive deep learning (DL) library. A short crash course on it will be given in Chapter 3.
- **PyTorch Ignite**: This is a set of high-level tools on top of PyTorch used to reduce boilerplate code. It will be covered briefly in Chapter 3. The full documentation is available here: [https://pytorch-ignite.ai/](https://pytorch-ignite.ai/).
- **PTAN**: (https://github.com/Shmuma/ptan) This is an open-source extension to the OpenAI Gym API that I created to support modern deep RL methods and building blocks. All classes used will be described in detail together with the source code.

Other libraries will be used for specific chapters; for example, we will use Microsoft TextWorld to play textbased
games, PyBullet and MuJoCo for robotic simulations, Selenium for browser-based automation problems,
and so on. Those specialized chapters will include installation instructions for those libraries.
A significant portion of this book (Parts 2, 3, and 4) is focused on the modern deep RL methods that have been
developed over the past few years. The word ‚Äúdeep‚Äù in this context means that DL is heavily used. You may be
aware that DL methods are computationally hungry. One modern graphics processing unit (GPU) can be
10 to 100 times faster than even the fastest multiple central processing unit (CPU) systems. In practice, this
means that the same code that takes one hour to train on a system with a GPU could take from half a day to
one week even on the fastest CPU system. It doesn‚Äôt mean that you can‚Äôt try the examples from this book
without having access to a GPU, but it will take longer. To experiment with the code on your own (the most
useful way to learn anything), it is better to get access to a machine with a GPU. This can be done in various
ways:

- Buying a modern GPU suitable for CUDA and supported by the PyTorch framework
- Using cloud instances. Both Amazon Web Services and Google Cloud Platform can provide you with
GPU-powered instances
- Google Colab offers free GPU access to its Jupyter notebooks
To give you the exact versions of the external dependencies that we will use throughout the book, here is a
requirements.txt file (please not that it was tested on Python 3.11; different versions might require you to
tweak the dependencies or not work at all):

```[text]
gymnasium[atari]==0.29.1
gymnasium[classic-control]==0.29.1
gymnasium[accept-rom-license]==0.29.1
moviepy==1.0.3
numpy<2
opencv-python==4.10.0.84
torch==2.5.0
torchvision==0.20.0
pytorch-ignite==0.5.1
tensorboard==2.18.0
mypy==1.8.0
ptan==0.8.1
stable-baselines3==2.3.2
torchrl==0.6.0
ray[tune]==2.37.0
pytest
```

    
  </details>
    


<details> 
  <summary><h2>Get to know Author</h2></summary>

_Maxim Lapan_ Maxim has been working as a software developer for more than 20 years and was involved in various areas: distributed scientific computing, distributed systems and big data processing. Since 2014 he is actively using machine and deep learning to solve practical industrial tasks, such as NLP problems, RL for web crawling and web pages analysis. He has been living in Germany with his family.

</details>
<details> 
  <summary><h2>Other Related Books</h2></summary>
<ul>

  <li><a href="https://www.packtpub.com/en-us/product/mastering-pytorch-second-edition/9781801074308">Mastering PyTorch, Second Edition</a></li>

  <li><a href="https://www.packtpub.com/en-us/product/python-for-algorithmic-trading-cookbook-first-edition/9781835084700">Python for Algorithmic Trading Cookbook, First Edition</a></li>
 
</ul>

</details>
